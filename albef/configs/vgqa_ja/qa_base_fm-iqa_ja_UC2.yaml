
train_file:  '/remote-home/zjli/CVLM/datasets/FM-IQA/train.json' #'/remote-home/zjli/CVLM/datasets/GQA/questions/train_all_questions/train_all_questions_*.json'
val_file: '/remote-home/zjli/CVLM/datasets/FM-IQA/val.json'       
test_file: '/remote-home/zjli/CVLM/datasets/FM-IQA/val.json'
image_root: 
  remote: '/remote-home/zjli/CVLM/pretrain_datasets/vg/VG_100K/' #flickr30k-images/
  local: 
    train:
      img_db: '/root/tmp_db/coco_train2014/feat_th0.2_max100_min10/'
      num2bb: '/root/tmp_db/coco_train2014/nbb_th0.2_max100_min10.json'
    val:
      img_db: '/root/tmp_db/coco_val2014/feat_th0.2_max100_min10/'
      num2bb: '/root/tmp_db/coco_val2014/nbb_th0.2_max100_min10.json'
bert_config: 'albef/configs/config_uc2.json'

image_res: 384
batch_size_train: 32
batch_size_test: 64

vision_width: 768
embed_dim: 256
temp: 0.07
k_test: 128
text_encoder: 'bert-base-uncased'
freeze_module: ['vis_encoder']
model_type: 'classification' # or generation
answer_num: 3001

alpha: 0.4
distill: True
warm_up: True

optimizer: {opt: adamW, lr: 3e-5, weight_decay: 0.02} 
schedular: {sched: cosine, lr: 1e-5, epochs: 10, min_lr: 1e-6, decay_rate: 1, warmup_lr: 1e-5, warmup_epochs: 1, cooldown_epochs: 0}